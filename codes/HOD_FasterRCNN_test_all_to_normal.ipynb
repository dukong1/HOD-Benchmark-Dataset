{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3284b0-079f-4a94-9fa1-7b8f85a4cad0",
   "metadata": {},
   "source": [
    "Code Author: Ha Eungyeom (eungyeom_ha@yonsei.ac.kr)        \n",
    "This code is developed for training and evaluating a Faster-RCNN model on the HOD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5920d96-4a85-420f-aa0f-32f61eced38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e5f91-0cd9-4a64-bae8-70a14a63319b",
   "metadata": {},
   "source": [
    "### Applying Inference and Evaluation on the Test Dataset : Normal Cases\r\n",
    "* Creating the test Dataset and DataLoader and calling single_gpu_test() to return the inference results. An error occurs in single_gpu_test() if batch_size is not set to 1.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2084e-640a-4518-80bc-160e2d8e4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.runner import HOOKS, Hook\n",
    "\n",
    "# Defining a new hook class for saving the best checkpoint based on the evaluation metric.\n",
    "@HOOKS.register_module()\n",
    "class SaveBestCheckpointHook(Hook):\n",
    "    def __init__(self, out_dir, metric='bbox_mAP_50', save_optimizer=True): #  metric='bbox_mAP\n",
    "        self.out_dir = out_dir\n",
    "        self.metric = metric\n",
    "        self.save_optimizer = save_optimizer\n",
    "        self.best_score = 0.0\n",
    "\n",
    "    def after_train_epoch(self, runner):\n",
    "        # Check and save the best model checkpoint after each training epoch based on the evaluation metric.\n",
    "        if not self.every_n_epochs(runner, 1):\n",
    "            return\n",
    "        from mmcv.runner import save_checkpoint\n",
    "        if runner.log_buffer.output.get(self.metric, 0) > self.best_score:\n",
    "            self.best_score = runner.log_buffer.output[self.metric]\n",
    "            save_checkpoint(runner.model, self.out_dir, optimizer=self.save_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217f773-3d26-4186-8aeb-790c688e3653",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '/rcnn_all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853925e1-0c56-42b7-a34d-931a99a03072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.coco import CocoDataset\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "# Registering a new dataset class based on the CocoDataset class.\n",
    "@DATASETS.register_module(force=True)\n",
    "class HOD(CocoDataset):\n",
    "    CLASSES = ('alcohol', 'insulting_gesture', 'blood', 'cigarette', 'gun', 'knife') \n",
    "\n",
    "config_file = './mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n",
    "\n",
    "cfg = Config.fromfile(config_file)\n",
    "\n",
    "# Modifying the dataset-related configurations. \n",
    "cfg.dataset_type = 'HOD'\n",
    "cfg.data_root = './faster_rcnn_data' + name\n",
    "\n",
    "# Updating the type, data_root, ann_file, img_prefix configurations for the train, val, and test datasets.. \n",
    "cfg.data.train.type = 'HOD'\n",
    "cfg.data.train.data_root = './faster_rcnn_data'+ name\n",
    "cfg.data.train.ann_file = 'train.json'\n",
    "cfg.data.train.img_prefix = 'JPEGImages'\n",
    "\n",
    "cfg.data.val.type = 'HOD'\n",
    "cfg.data.val.data_root = './faster_rcnn_data' + name\n",
    "cfg.data.val.ann_file = 'val.json'\n",
    "cfg.data.val.img_prefix = 'JPEGImages'\n",
    "\n",
    "cfg.data.test.type = 'HOD'\n",
    "cfg.data.test.data_root = './faster_rcnn_data' + '/rcnn_normal/' # normal cases \n",
    "cfg.data.test.ann_file = 'test.json'\n",
    "cfg.data.test.img_prefix = 'JPEGImages'\n",
    "\n",
    "# Updating the number of classes.\n",
    "cfg.model.roi_head.bbox_head.num_classes = 6\n",
    "# Pretrained model\n",
    "cfg.load_from = './mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "\n",
    "# Setting the directory for saving the logs of training weights.\n",
    "cfg.work_dir = './tutorial_exps_normal'\n",
    "\n",
    "# Updating the learning rate configurations.\n",
    "cfg.optimizer.lr = 0.02 / 8\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.log_config.interval = 2000\n",
    "\n",
    "# For CocoDataset, the metric should be set to 'bbox' (instead of mAP). Setting it to 'bbox' calculates mAP over a range of IoU thresholds (0.5 to 0.95)\n",
    "cfg.evaluation.metric = 'bbox'\n",
    "cfg.evaluation.interval = 2000\n",
    "cfg.checkpoint_config.interval = 5\n",
    "cfg.custom_hooks = [dict(type='SaveBestCheckpointHook', out_dir=cfg.work_dir, metric='bbox_mAP', save_optimizer=True)]\n",
    "\n",
    "# Due to a bug(?), set the samples_per_gpu to 1 for test dataset evaluation. In the data loader, the batch size is determined by the number of GPUs.\n",
    "cfg.data.samples_per_gpu = 1\n",
    "\n",
    "# Due to an error where loading the config twice causes the lr_config's policy to disappear, it's set again here.\n",
    "cfg.lr_config.policy='step'\n",
    "# Set the seed for more reproducible results.\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.custom_hooks = [dict(type='SaveBestCheckpointHook', out_dir=cfg.work_dir, metric='bbox_mAP', save_optimizer=True)]\n",
    "\n",
    "# Addition by Eunkyeom\n",
    "# Change the evaluation metric since we use a customized dataset.\n",
    "cfg.device = 'cuda'\n",
    "cfg.runner.max_epochs = 150\n",
    "\n",
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada60409-3b7b-4e6a-a6f3-d80a539f0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dump('./tutorial_exps_all/HOD_faster_rcnn_conf_all.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808dd13-b283-428e-9631-7fd82fe7e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./show_test_output_all_to_normal # Create a directory to save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe18d9e-04b9-4521-82d9-3e71ec1981f3",
   "metadata": {
    "id": "_Hvk9Ut5ji1e"
   },
   "source": [
    "### Setting up the test dataset and dataloader separately, and loading the trained checkpoint model for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecafadd-de91-4e39-9d13-a2a17a6dd27c",
   "metadata": {
    "id": "TDcbOV6mRlkf"
   },
   "outputs": [],
   "source": [
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "# Creating the test Dataset and DataLoader.\n",
    "# Unlike when creating the train dataset, do not wrap build_dataset() in a list. \n",
    "dataset = build_dataset(cfg.data.test) \n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        # Must set the samples_per_gpu argument value to 1\n",
    "        # samples_per_gpu=cfg.data.samples_per_gpu,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "\n",
    "# Must ensure that the 'img' key value is output as a tensor.\n",
    "next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a3b68-c992-4b0c-92e4-5a06e3bb395f",
   "metadata": {
    "id": "Y2sJiFuzV9Fc"
   },
   "outputs": [],
   "source": [
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "\n",
    "checkpoint_file = './tutorial_exps_all/latest.pth'\n",
    "\n",
    "# Using the checkpoint saved model file to create a model, using the above updated config.\n",
    "# Load model\n",
    "model_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7e09f-b776-4712-a439-e7a51c472e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import multi_gpu_test, single_gpu_test\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "\n",
    "model_ckpt = MMDataParallel(model_ckpt, device_ids=[0])\n",
    "\n",
    "# Calling single_gpu_test() to perform inference on the test dataset. Must set the batch size to 1.\n",
    "# The inference results are saved as visualized images in the /kaggle/working/show_test_output directory.\n",
    "# Set the threshold properly to 0.5 !!!\n",
    "outputs = single_gpu_test(model_ckpt, data_loader, True, './show_test_output_all_to_normal', 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e80ea0-9b2e-4dfe-8e46-67fd553505ad",
   "metadata": {
    "id": "Oi7gIuYimGkK"
   },
   "source": [
    "### Checking the returned inference applied results of the test dataset and performing performance evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6191b-5805-41e4-b7bb-2dd2d5102a20",
   "metadata": {
    "id": "6YgUFo2c6pWr"
   },
   "outputs": [],
   "source": [
    "print('Result outputs type:', type(outputs))\n",
    "print('Number of evaluated files:', len(outputs))\n",
    "print('Type of the first evaluation result:', type(outputs[0]))\n",
    "print('Number of CLASSES in the first evaluation result:', len(outputs[0]))\n",
    "print('Type and shape of CLASS ID 0 in the first evaluation result:', type(outputs[0][0]), outputs[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5cc3d-b04c-466c-8e1b-616cb97fa804",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dataset.evaluate(outputs, metric='bbox', classwise=True) # AP0.05 ~ 0.95\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3268be-4cd4-4461-a4df-25468513c32e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# Function to filter out the detection outputs based on confidence thresholds.\n",
    "def filter_outputs_by_confidence(outputs, confidence_threshold):\n",
    "    filtered_outputs = []\n",
    "    for output_per_image in outputs:\n",
    "        filtered_output_per_image = []\n",
    "        for class_index, boxes in enumerate(output_per_image):\n",
    "            if len(boxes) == 0:\n",
    "                filtered_output_per_image.append(np.array([]))\n",
    "                continue\n",
    "            # Filtering the boxes based on the confidence score.\n",
    "            filtered_boxes = boxes[boxes[:, 4] >= confidence_threshold]\n",
    "            filtered_output_per_image.append(filtered_boxes)\n",
    "        filtered_outputs.append(filtered_output_per_image)\n",
    "    return filtered_outputs\n",
    "\n",
    "# Calling single_gpu_test only once to obtain the results.\n",
    "outputs = single_gpu_test(model_ckpt, data_loader, True, './show_test_output_all_to_normal', 0.5)\n",
    "\n",
    "best_threshold = 0.0  # Variable to store the threshold with the highest mAP50 value.\n",
    "best_mAP50 = 0.0  # Variable to store the highest mAP50 value.\n",
    "\n",
    "for con_fi in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    print(con_fi)\n",
    "    # Filtering the previously obtained outputs.\n",
    "    filtered_outputs = filter_outputs_by_confidence(copy.deepcopy(outputs), con_fi)\n",
    "    # Evaluating the metrics for the filtered outputs.\n",
    "    metric = dataset.evaluate(filtered_outputs, metric='bbox', classwise=True)  # AP0.05 ~ 0.95\n",
    "    metric_50 = dataset.evaluate(filtered_outputs, metric='bbox', classwise=True, iou_thrs=[0.5])\n",
    "    \n",
    "    # Updating the best mAP50 value and the corresponding threshold if the current mAP50 value is higher.\n",
    "    current_mAP50 = metric_50['bbox_mAP']\n",
    "    if current_mAP50 > best_mAP50:\n",
    "        best_mAP50 = current_mAP50\n",
    "        best_threshold = con_fi\n",
    "    \n",
    "    print(metric)\n",
    "    print()\n",
    "    print(metric_50)\n",
    "    print(\"=============================================================================================================\")\n",
    "\n",
    "# Converting the threshold value with the highest mAP50 to a string.\n",
    "best_threshold_str = str(best_threshold).replace('.', '_')\n",
    "# Saving the results to a JSON file.\n",
    "with open(f'results_conf_{best_threshold_str}.json', 'w') as f:\n",
    "    json.dump({'best_threshold': best_threshold, 'best_mAP50': best_mAP50}, f)\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold}, Best mAP50: {best_mAP50}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egha-mm",
   "language": "python",
   "name": "egha-mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
